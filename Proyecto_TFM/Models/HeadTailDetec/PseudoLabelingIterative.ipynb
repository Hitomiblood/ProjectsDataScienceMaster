{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PseudoLabeling Manual"
      ],
      "metadata": {
        "id": "pqYgI_07Ucui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "5FCBoA_-UcSx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget https://www.dropbox.com/scl/fi/3mwyjefpr86kqktwrs1dh/HeadBest.pt?rlkey=b1h3rsr1z4cb82yh2najhvmrj&st=k4l2wefe&dl=0\n",
        "!mv HeadBest.pt?rlkey=b1h3rsr1z4cb82yh2najhvmrj HeadBest.pt"
      ],
      "metadata": {
        "id": "H_C9dV5pUsAG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget https://www.dropbox.com/scl/fi/ejtve3v8cggqo1d7vfmr9/dataSetUnlabel.zip?rlkey=lyun664rceo9shrfie7rh9wsc&st=aldjww59&dl=0\n",
        "!mv dataSetUnlabel.zip?rlkey=lyun664rceo9shrfie7rh9wsc dataSetUnlabel.zip\n",
        "!unzip dataSetUnlabel.zip"
      ],
      "metadata": {
        "id": "SJr9fjF7Uu7y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Cargar el modelo preentrenado\n",
        "model = YOLO('HeadBest.pt')\n"
      ],
      "metadata": {
        "id": "Dk24YbmJ9Q-e"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Definir las rutas a los directorios\n",
        "base_dir = '/content/dataSet'  # Reemplaza esto con la ruta correcta\n",
        "unlabel_dir = os.path.join(base_dir, 'Unlabel')\n",
        "train_images_dir = os.path.join(base_dir, 'images', 'train')\n",
        "train_labels_dir = os.path.join(base_dir, 'labels', 'train')\n",
        "processed_images_file = os.path.join(base_dir, 'processed_images.txt')\n",
        "\n",
        "# Crear los directorios de destino si no existen\n",
        "os.makedirs(train_images_dir, exist_ok=True)\n",
        "os.makedirs(train_labels_dir, exist_ok=True)\n",
        "\n",
        "def load_processed_images(processed_images_file):\n",
        "    if os.path.exists(processed_images_file):\n",
        "        with open(processed_images_file, 'r') as f:\n",
        "            return set(line.strip() for line in f)\n",
        "    return set()\n",
        "\n",
        "def save_processed_images(processed_images_file, processed_images):\n",
        "    with open(processed_images_file, 'w') as f:\n",
        "        for image_path in processed_images:\n",
        "            f.write(f\"{image_path}\\n\")\n",
        "\n",
        "def get_unlabeled_images(batch_size=100):\n",
        "    processed_images = load_processed_images(processed_images_file)\n",
        "    all_images = [os.path.join(unlabel_dir, f) for f in os.listdir(unlabel_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "\n",
        "    # Filtrar las imágenes ya procesadas y verificar existencia\n",
        "    unprocessed_images = [img for img in all_images if img not in processed_images and os.path.exists(img)]\n",
        "\n",
        "    # Seleccionar secuencialmente las primeras `batch_size` imágenes no procesadas\n",
        "    return unprocessed_images[:batch_size]\n",
        "\n",
        "def predict_and_label_images(images, model, confidence_threshold=0.7):\n",
        "    labeled_images = []\n",
        "\n",
        "    for image_path in images:\n",
        "        results = model.predict(image_path, conf=confidence_threshold, verbose=False)\n",
        "\n",
        "        for result in results:\n",
        "            boxes = result.boxes\n",
        "            confs = boxes.conf.cpu().numpy()\n",
        "            clss = boxes.cls.cpu().numpy()\n",
        "            data = boxes.xywhn.cpu().numpy()\n",
        "\n",
        "            for conf, box, cls in zip(confs, data, clss):\n",
        "                if conf >= confidence_threshold:\n",
        "                    class_id = cls  # La clase está en el quinto valor\n",
        "                    x_center, y_center, width, height = box[:4]  # Coordenadas de la caja\n",
        "                    labeled_images.append((image_path, int(class_id), x_center, y_center, width, height))\n",
        "\n",
        "    return labeled_images\n",
        "\n",
        "def save_predictions(predicted_labels, train_images_dir, train_labels_dir, processed_images):\n",
        "    for image_path, class_id, x_center, y_center, width, height in predicted_labels:\n",
        "        # Verificar si la imagen aún existe\n",
        "        if not os.path.exists(image_path):\n",
        "            continue\n",
        "\n",
        "        # Generar un nuevo nombre de archivo basado en los existentes en la carpeta de entrenamiento\n",
        "        image_filename = os.path.basename(image_path)\n",
        "        new_image_path = os.path.join(train_images_dir, image_filename)\n",
        "\n",
        "        if os.path.exists(new_image_path):\n",
        "            base_name, ext = os.path.splitext(image_filename)\n",
        "            counter = 1\n",
        "            new_image_path = os.path.join(train_images_dir, f\"{base_name}_{counter}{ext}\")\n",
        "            while os.path.exists(new_image_path):\n",
        "                counter += 1\n",
        "                new_image_path = os.path.join(train_images_dir, f\"{base_name}_{counter}{ext}\")\n",
        "\n",
        "        # Mover la imagen al directorio de entrenamiento\n",
        "        shutil.move(image_path, new_image_path)\n",
        "\n",
        "        # Guardar las etiquetas en el formato YOLO\n",
        "        label_path = os.path.join(train_labels_dir, f\"{os.path.splitext(image_filename)[0]}.txt\")\n",
        "        with open(label_path, 'w') as f:\n",
        "            f.write(f\"{int(class_id)} {x_center} {y_center} {width} {height}\\n\")\n",
        "\n",
        "        # Añadir la imagen al conjunto de imágenes procesadas\n",
        "        processed_images.add(image_path)\n",
        "\n",
        "def pseudolabeling_iteration(model, num_iterations=5, batch_size=100, confidence_threshold=0.7):\n",
        "    processed_images = load_processed_images(processed_images_file)\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        print(f\"Iteración {i+1}/{num_iterations}\")\n",
        "\n",
        "        # Seleccionar un lote de imágenes sin etiquetar\n",
        "        unlabeled_images = get_unlabeled_images(batch_size)\n",
        "\n",
        "        if not unlabeled_images:\n",
        "            print(\"No quedan más imágenes sin etiquetar.\")\n",
        "            break\n",
        "\n",
        "        # Obtener las predicciones para el lote de imágenes\n",
        "        predicted_labels = predict_and_label_images(unlabeled_images, model, confidence_threshold)\n",
        "\n",
        "        # Guardar las predicciones y mover las imágenes etiquetadas\n",
        "        save_predictions(predicted_labels, train_images_dir, train_labels_dir, processed_images)\n",
        "\n",
        "        # Guardar el estado de las imágenes procesadas\n",
        "        save_processed_images(processed_images_file, processed_images)\n",
        "\n",
        "# Ejecutar el proceso de pseudolabeling\n",
        "pseudolabeling_iteration(model, num_iterations=5, batch_size=100, confidence_threshold=0.7)\n"
      ],
      "metadata": {
        "id": "yxPh8LSp-Bhi",
        "outputId": "1be4d5d0-9521-4b79-aa41-a60697950e2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteración 1/5\n",
            "Iteración 2/5\n",
            "Iteración 3/5\n",
            "Iteración 4/5\n",
            "Iteración 5/5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.make_archive('images', 'zip',train_images_dir)\n",
        "shutil.make_archive('labels', 'zip',train_labels_dir)"
      ],
      "metadata": {
        "id": "UtMYCQbyjm_6",
        "outputId": "03bfc862-bcdb-4c06-dbd0-e56e1d5950b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/labels.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}