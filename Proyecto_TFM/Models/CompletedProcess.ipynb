{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://www.dropbox.com/scl/fi/maqbuw2e0s7ywa63dofun/bestSmall1920.pt?rlkey=n0pqsnjgycak6v7jx3qzhladt&st=04t3nonx&dl=0\n",
    "!mv bestSmall1920.pt?rlkey=n0pqsnjgycak6v7jx3qzhladt bestSmall1920.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://www.dropbox.com/scl/fi/3mwyjefpr86kqktwrs1dh/HeadBest.pt?rlkey=b1h3rsr1z4cb82yh2najhvmrj&st=k4l2wefe&dl=0\n",
    "!mv HeadBest.pt?rlkey=b1h3rsr1z4cb82yh2najhvmrj HeadBest.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained YOLO model (recommended for training)\n",
    "model = YOLO('bestSmall1920.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained YOLO model (recommended for training)\n",
    "modelHeads = YOLO('HeadBest.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Descargar el archivo ZIP desde la URL\n",
    "!wget https://www.dropbox.com/scl/fi/wgyl8ibb6rgo04ezuhzd5/Suppl_1.zip?rlkey=rmme7la6j6593wuacwiap8j46&st=qvcm3x1k&dl=0\n",
    "\n",
    "# Crear la carpeta \"Videos\" si no existe\n",
    "!mkdir -p Videos\n",
    "\n",
    "!mv Suppl_1.zip?rlkey=rmme7la6j6593wuacwiap8j46 Suppl_1.zip\n",
    "\n",
    "# Descomprimir el archivo ZIP en la carpeta \"Videos\"\n",
    "!unzip -o Suppl_1.zip -d Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "cv2.imshow = cv2_imshow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio de entrada y salida\n",
    "input_folder = \"Videos/\"\n",
    "output_folder = \"output_videos/\"\n",
    "\n",
    "# Crear el directorio de salida si no existe\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Listar los archivos de video en el directorio de entrada\n",
    "video_files = [f for f in os.listdir(input_folder) if os.path.isfile(os.path.join(input_folder, f))]\n",
    "\n",
    "# Iterar sobre cada archivo de video\n",
    "for video_file in video_files:\n",
    "    # Abrir el archivo de video de entrada\n",
    "    video_path = os.path.join(input_folder, video_file)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Verificar si la apertura del video fue exitosa\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error al abrir el archivo de video: {video_file}\")\n",
    "        continue\n",
    "\n",
    "    # Obtener información del video de entrada\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_size = (frame_width, frame_height)\n",
    "\n",
    "    # Crear el objeto VideoWriter para el video de salida\n",
    "    output_video_file = os.path.join(output_folder, f\"{os.path.splitext(video_file)[0]}_Out.avi\")\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')  # Formato de compresión de vídeo\n",
    "    out = cv2.VideoWriter(output_video_file, fourcc, fps, frame_size)\n",
    "\n",
    "    # Store the track history\n",
    "    track_history = defaultdict(lambda: [])\n",
    "    head_track_history = defaultdict(lambda: [])\n",
    "    last_head_position = defaultdict(lambda: None)\n",
    "\n",
    "    model = YOLO('bestSmall1920.pt')\n",
    "\n",
    "    # Loop through the video frames\n",
    "    while cap.isOpened():\n",
    "        # Leer un cuadro del video\n",
    "        success, frame = cap.read()\n",
    "\n",
    "        if success:\n",
    "            # Ejecutar el seguimiento YOLOv8 en el cuadro, persistiendo los tracks entre cuadros\n",
    "            results = model.track(frame, persist=True)\n",
    "\n",
    "            # Verificar si se detectaron resultados\n",
    "            if results and len(results) > 0 and len(results[0].boxes) > 0:\n",
    "                # Obtener las cajas y los IDs de seguimiento\n",
    "                boxes = results[0].boxes.xywh.cpu()\n",
    "                track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "\n",
    "                # Visualizar los resultados en el cuadro\n",
    "                annotated_frame = results[0].plot()\n",
    "\n",
    "                # Dibujar las líneas de seguimiento\n",
    "                for box, track_id in zip(boxes, track_ids):\n",
    "                    x, y, w, h = box\n",
    "                    track = track_history[track_id]\n",
    "                    track.append((float(x), float(y)))  # x, y centro\n",
    "                    if len(track) > 80:  # mantiene 80 tracks por 80 cuadros\n",
    "                        track.pop(0)\n",
    "\n",
    "                    # ************* Apartado a modificar *************\n",
    "                    ################################################\n",
    "                    # Recortar la región de interés (ROI) del cuadro original\n",
    "                    roi = frame[int(y-h/2):int(y+h/2), int(x-w/2):int(x+w/2)]\n",
    "\n",
    "                    # Inicializar variable para almacenar la nueva posición de la cabeza\n",
    "                    new_head_position = None\n",
    "\n",
    "                    # Verificar que el ROI no esté vacío\n",
    "                    if roi.size != 0:\n",
    "                        # Ejecutar el modelo de detección de cabezas en el ROI\n",
    "                        head_results = modelHeads(roi)\n",
    "                        \n",
    "                        # Obtener las detecciones de cabezas\n",
    "                        if head_results and len(head_results[0].boxes) > 0:\n",
    "                            head_boxes = head_results[0].boxes.xywh.cpu().numpy()\n",
    "                            for head_box in head_boxes:\n",
    "                                if head_box[5] == 0:  # Si la clase es 0\n",
    "                                    hx, hy, hw, hh = head_box[:4]\n",
    "                                    head_center_x = x - w/2 + hx\n",
    "                                    head_center_y = y - h/2 + hy\n",
    "                                    \n",
    "                                    new_head_position = (float(head_center_x), float(head_center_y))\n",
    "                                    \n",
    "                                    # Dibujar la caja de la cabeza en el cuadro original\n",
    "                                    cv2.rectangle(frame,\n",
    "                                                  (int(head_center_x - hw/2), int(head_center_y - hh/2)),\n",
    "                                                  (int(head_center_x + hw/2), int(head_center_y + hh/2)),\n",
    "                                                  (255, 0, 0), 2)\n",
    "\n",
    "                    # Si no se detectó una nueva cabeza, utilizar la última posición conocida\n",
    "                    if new_head_position is None and last_head_position[track_id] is not None:\n",
    "                        new_head_position = last_head_position[track_id]\n",
    "\n",
    "                    # Actualizar la última posición conocida de la cabeza\n",
    "                    if new_head_position is not None:\n",
    "                        head_track = head_track_history[track_id]\n",
    "                        head_track.append(new_head_position)\n",
    "                        last_head_position[track_id] = new_head_position  # Actualizar la última posición conocida\n",
    "                        if len(head_track) > 80:  # mantener 80 tracks por 80 cuadros\n",
    "                            head_track.pop(0)\n",
    "                    ################################################\n",
    "\n",
    "                    # Dibujar las líneas de seguimiento\n",
    "                    points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "                    cv2.polylines(frame, [points], isClosed=False, color=(0, 255, 255), thickness=3)\n",
    "\n",
    "                    # Dibujar las líneas de seguimiento de las cabezas\n",
    "                    head_points = np.hstack(head_track_history[track_id]).astype(np.int32).reshape((-1, 1, 2))\n",
    "                    cv2.polylines(frame, [head_points], isClosed=False, color=(255, 0, 0), thickness=3)\n",
    "\n",
    "                # Escribir el cuadro procesado en el archivo de salida\n",
    "                out.write(frame)\n",
    "            else:\n",
    "                # Si no se detectaron resultados, escribir el cuadro original en el archivo de salida\n",
    "                out.write(frame)\n",
    "\n",
    "        else:\n",
    "            # Terminar la ejecución si se alcanza el final del video\n",
    "            break\n",
    "\n",
    "    # Liberar los recursos\n",
    "    cap.release()\n",
    "    out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
